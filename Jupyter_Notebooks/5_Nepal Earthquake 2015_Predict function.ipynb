{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2WSS0NLf7Ft"
   },
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "hcXN2Y_ue5gj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import joblib\n",
    "from scipy import stats\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, BatchNormalization, Reshape, Concatenate\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhipHLkuDXF6"
   },
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3k2eO2DE1Ofw"
   },
   "outputs": [],
   "source": [
    "filepath = '/notebooks/EQ Damage Prediction Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "executionInfo": {
     "elapsed": 4209,
     "status": "ok",
     "timestamp": 1627828551533,
     "user": {
      "displayName": "kiran m",
      "photoUrl": "",
      "userId": "12559345382288346746"
     },
     "user_tz": -330
    },
    "id": "EsrWOFWBDYzq",
    "outputId": "2ababd22-2452-4edf-9ae0-df8038f82308"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>vdcmun_id</th>\n",
       "      <th>ward_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age_building</th>\n",
       "      <th>plinth_area_sq_ft</th>\n",
       "      <th>height_ft_pre_eq</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_asset_cable_pre_eq</th>\n",
       "      <th>has_asset_computer_pre_eq</th>\n",
       "      <th>has_asset_internet_pre_eq</th>\n",
       "      <th>has_asset_telephone_pre_eq</th>\n",
       "      <th>has_asset_mobile_phone_pre_eq</th>\n",
       "      <th>has_asset_fridge_pre_eq</th>\n",
       "      <th>has_asset_motorcycle_pre_eq</th>\n",
       "      <th>has_asset_four_wheeler_family_use_pre_eq</th>\n",
       "      <th>has_asset_four_wheeler_commercial_use_pre_eq</th>\n",
       "      <th>has_asset_none_pre_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2409</td>\n",
       "      <td>240908</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>368</td>\n",
       "      <td>21</td>\n",
       "      <td>Moderate slope</td>\n",
       "      <td>Mud mortar-Stone/Brick</td>\n",
       "      <td>Bamboo/Timber-Light roof</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3009</td>\n",
       "      <td>300902</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>Flat</td>\n",
       "      <td>Mud mortar-Stone/Brick</td>\n",
       "      <td>Bamboo/Timber-Heavy roof</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   district_id  vdcmun_id  ward_id  count_floors_pre_eq  age_building  \\\n",
       "0           24       2409   240908                    2            30   \n",
       "1           30       3009   300902                    3            25   \n",
       "\n",
       "   plinth_area_sq_ft  height_ft_pre_eq land_surface_condition  \\\n",
       "0                368                21         Moderate slope   \n",
       "1                300                30                   Flat   \n",
       "\n",
       "          foundation_type                 roof_type  ...  \\\n",
       "0  Mud mortar-Stone/Brick  Bamboo/Timber-Light roof  ...   \n",
       "1  Mud mortar-Stone/Brick  Bamboo/Timber-Heavy roof  ...   \n",
       "\n",
       "  has_asset_cable_pre_eq has_asset_computer_pre_eq has_asset_internet_pre_eq  \\\n",
       "0                      0                         0                         0   \n",
       "1                      0                         0                         0   \n",
       "\n",
       "  has_asset_telephone_pre_eq  has_asset_mobile_phone_pre_eq  \\\n",
       "0                          0                              1   \n",
       "1                          0                              1   \n",
       "\n",
       "   has_asset_fridge_pre_eq  has_asset_motorcycle_pre_eq  \\\n",
       "0                        0                            0   \n",
       "1                        0                            0   \n",
       "\n",
       "   has_asset_four_wheeler_family_use_pre_eq  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "\n",
       "   has_asset_four_wheeler_commercial_use_pre_eq  has_asset_none_pre_eq  \n",
       "0                                             0                      0  \n",
       "1                                             0                      0  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = joblib.load(filepath+'test_data/test_data.pkl')\n",
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIq2_LxgGL3Q"
   },
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "XCEvn7jbgkJe"
   },
   "outputs": [],
   "source": [
    "def predict(test_df):\n",
    "    '''This function predicts the severity of damage given the raw input dataframe'''\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        ''' This function preprocesses the categorical text feature '''\n",
    "\n",
    "        text = str(text).lower()            \n",
    "        text = re.sub(r'\\.', '', text)       \n",
    "        text = re.sub(r' |/|-', '_', text)   # Replace space or '/' or '-' chars by '_'\n",
    "        return text\n",
    "    \n",
    "    def get_embedded_data(embedding_matrix, test_data):\n",
    "        \n",
    "        cat_embed_names = joblib.load(filepath+'cat_embed_names.pkl')\n",
    "        test_embed = []  \n",
    "        for feat in list(embedding_matrix.keys()):\n",
    "            test_embed.append(embedding_matrix[feat][test_data[feat]])\n",
    "\n",
    "        test_embed = pd.DataFrame(np.concatenate(test_embed, axis=1), columns = cat_embed_names)\n",
    "        test_embed = pd.concat((test_embed, test_data[int_dtypes]), axis=1)\n",
    "\n",
    "        return test_embed\n",
    "    \n",
    "    # Preprocessing numerical features\n",
    "    int_dtypes = joblib.load(filepath+'num_feat.pkl')\n",
    "    test_df[int_dtypes] = test_df[int_dtypes].astype(int)\n",
    "    boxcox_fit_lambdas = joblib.load(filepath+'boxcox_fit_lambdas.pkl')\n",
    "    \n",
    "    num_preprocessing_features = ['age_building','plinth_area_sq_ft','height_ft_pre_eq',\n",
    "                                'age_household_head','size_household']\n",
    "    for feature in num_preprocessing_features:\n",
    "        test_df[feature] = stats.boxcox(test_df[feature]+1, boxcox_fit_lambdas['lambda_'+feature])\n",
    "\n",
    "    # Preprocessing categorical features\n",
    "    object_dtypes = joblib.load(filepath+'cat_feat.pkl')       \n",
    "    for feature in object_dtypes:\n",
    "        test_df[feature] = test_df[feature].apply(preprocess_text)\n",
    "        tokenizer = joblib.load(filepath+'tokenizers/'+feature+'_tokenizer.pkl')\n",
    "        test_df[feature] = np.array(tokenizer.texts_to_sequences(test_df[feature])).ravel()\n",
    "    \n",
    "    #Embedding the categorical features\n",
    "    embedding_matrix = joblib.load(filepath+'oversamp/embedding_matrix.pkl')\n",
    "    test_embed = get_embedded_data(embedding_matrix, test_df)\n",
    "    \n",
    "       \n",
    "    # Standard Scaling\n",
    "    scaler = joblib.load(filepath+'oversamp/standard_scaler.pkl')\n",
    "    test_embed_std = scaler.transform(test_embed)\n",
    "    test_embed_std = pd.DataFrame(test_embed_std, columns=test_embed.columns)\n",
    "\n",
    "    # Load best model and predict\n",
    "    model = joblib.load(filepath+'/models/LGB_model.pkl')\n",
    "    predictions = model.predict(test_embed_std)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36873,
     "status": "ok",
     "timestamp": 1627828588397,
     "user": {
      "displayName": "kiran m",
      "photoUrl": "",
      "userId": "12559345382288346746"
     },
     "user_tz": -330
    },
    "id": "FWP7UF-tGWbm",
    "outputId": "dbd5449f-fc42-4735-dbd7-cfab03165859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    74541\n",
       "0    24375\n",
       "1    13153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(X_test)\n",
    "pd.DataFrame(pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sss299AMGPDZ"
   },
   "source": [
    "## Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = joblib.load(filepath+'test_data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Rds_ZnY-EU5b"
   },
   "outputs": [],
   "source": [
    "def f1_micro(test_df, target, print_classification_report=True):\n",
    "    '''This function predicts the severity of damage and returns micro_f1 score of its prediction and prints classification report if True'''\n",
    "    \n",
    "    def preprocess_text(text):\n",
    "        ''' This function preprocesses the categorical text feature '''\n",
    "\n",
    "        text = str(text).lower()            \n",
    "        text = re.sub(r'\\.', '', text)       \n",
    "        text = re.sub(r' |/|-', '_', text)   # Replace space or '/' or '-' chars by '_'\n",
    "        return text\n",
    "    \n",
    "    def get_embedded_data(embedding_matrix, test_data):\n",
    "        \n",
    "        cat_embed_names = joblib.load(filepath+'cat_embed_names.pkl')\n",
    "        test_embed = []  \n",
    "        for feat in list(embedding_matrix.keys()):\n",
    "            test_embed.append(embedding_matrix[feat][test_data[feat]])\n",
    "\n",
    "        test_embed = pd.DataFrame(np.concatenate(test_embed, axis=1), columns = cat_embed_names)\n",
    "        test_embed = pd.concat((test_embed, test_data[int_dtypes]), axis=1)\n",
    "\n",
    "        return test_embed\n",
    "    \n",
    "    # Preprocessing numerical features\n",
    "    int_dtypes = joblib.load(filepath+'num_feat.pkl')\n",
    "    test_df[int_dtypes] = test_df[int_dtypes].astype(int)\n",
    "    boxcox_fit_lambdas = joblib.load(filepath+'boxcox_fit_lambdas.pkl')\n",
    "    \n",
    "    num_preprocessing_features = ['age_building','plinth_area_sq_ft','height_ft_pre_eq',\n",
    "                                'age_household_head','size_household']\n",
    "    for feature in num_preprocessing_features:\n",
    "        test_df[feature] = stats.boxcox(test_df[feature]+1, boxcox_fit_lambdas['lambda_'+feature])\n",
    "\n",
    "    # Preprocessing categorical features\n",
    "    object_dtypes = joblib.load(filepath+'cat_feat.pkl')       \n",
    "    for feature in object_dtypes:\n",
    "        test_df[feature] = test_df[feature].apply(preprocess_text)\n",
    "        tokenizer = joblib.load(filepath+'tokenizers/'+feature+'_tokenizer.pkl')\n",
    "        test_df[feature] = np.array(tokenizer.texts_to_sequences(test_df[feature])).ravel()\n",
    "    \n",
    "    #Embedding the categorical features\n",
    "    embedding_matrix = joblib.load(filepath+'oversamp/embedding_matrix.pkl')\n",
    "    test_embed = get_embedded_data(embedding_matrix, test_df)\n",
    "    \n",
    "       \n",
    "    # Standard Scaling\n",
    "    scaler = joblib.load(filepath+'oversamp/standard_scaler.pkl')\n",
    "    test_embed_std = scaler.transform(test_embed)\n",
    "    test_embed_std = pd.DataFrame(test_embed_std, columns=test_embed.columns)\n",
    "\n",
    "    # Load best model and predict\n",
    "    model = joblib.load(filepath+'/models/LGB_model.pkl')\n",
    "    predictions = model.predict(test_embed_std)\n",
    "\n",
    "    # Scoring\n",
    "    target_mapping = {'Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "    target = target.map(target_mapping)\n",
    "    score = f1_score(target, predictions, average='micro')\n",
    "    \n",
    "    if print_classification_report:\n",
    "        print('\\n\\033[1mClassification report:\\033[0m')\n",
    "        print(classification_report(target, predictions))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23812,
     "status": "ok",
     "timestamp": 1627828635083,
     "user": {
      "displayName": "kiran m",
      "photoUrl": "",
      "userId": "12559345382288346746"
     },
     "user_tz": -330
    },
    "id": "3PqrQgXWF2FE",
    "outputId": "ba056576-5f7f-48cf-cfea-e3559bdc56d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mClassification report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74     23584\n",
      "           1       0.52      0.35      0.42     19825\n",
      "           2       0.83      0.91      0.87     68660\n",
      "\n",
      "    accuracy                           0.78    112069\n",
      "   macro avg       0.70      0.67      0.68    112069\n",
      "weighted avg       0.76      0.78      0.76    112069\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7750760692073633"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro(X_test, y_test, print_classification_report=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNYa1GppwxUcYm8gN06qF5c",
   "collapsed_sections": [],
   "mount_file_id": "1rOZ8TKxaqhBDs9vvWeMZ0hiJfA0Eps2b",
   "name": "5_Nepal Earthquake 2015_Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
